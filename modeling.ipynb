{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import defaultdict\n",
    "from collections import defaultdict\n",
    "\n",
    "# Numpy and pandas for manipulating the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib and seaborn for visualization\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# GridSearchCV for training \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Performance metrics from sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Prophet for time forecasting\n",
    "from fbprophet import Prophet\n",
    "\n",
    "# Classification models\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# To hide stdout because Prophet can be loud\n",
    "import logging\n",
    "logging.getLogger('fbprophet').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_file = './data/cleaned/feature.csv'\n",
    "by_date_total_file = './data/cleaned/by_date_total.csv'\n",
    "provisions_file = './data/raw/provisions.csv'\n",
    "useful_provisions_file = './data/cleaned/useful_provisions.csv'\n",
    "\n",
    "feature_df = pd.read_csv(feature_file, parse_dates=True, index_col=0)\n",
    "by_date_total_df = pd.read_csv(by_date_total_file, parse_dates=True, index_col=0)\n",
    "provisions_df = pd.read_csv(provisions_file, parse_dates=True)\n",
    "useful_provisions_df = pd.read_csv(useful_provisions_file, parse_dates=True, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing features\n",
    "There are still a couple of features to be tweaked. Although the data was cleaned in `clean-data` journal, it is more convenient to add the provisions features here, as they are likely to be changed along with changes to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add only the useful provisions to our feature_df (k from this year and k from n years prior)\n",
    "def add_provisions(feature_df, provisions_df, useful_provisions_df, k=30, n=5):\n",
    "    # Get the state and year columns for a join later and lawtotal to account for excluded provisions\n",
    "#     columns = list(useful_provisions_df.head(k)['provision'].values)\n",
    "    columns = list(useful_provisions_df.sort_values('diff').tail(k)['provision'].values)\n",
    "    columns.extend(['year', 'state', 'lawtotal'])     \n",
    "    \n",
    "    # Get the years \n",
    "    years = feature_df.groupby('this_year').count().index.values\n",
    "\n",
    "    # Keep track of provisions for this year and n years prior\n",
    "    current_provisions = []\n",
    "    old_provisions = []\n",
    "\n",
    "    # Add the provisions from each year to a list\n",
    "    for year in years:\n",
    "        current_provisions.append(provisions_df[provisions_df['year'] == year][columns])\n",
    "        old_provisions.append(provisions_df[provisions_df['year'] == year - n][columns])\n",
    "\n",
    "    # Put the provisions into a DataFrame\n",
    "    current_provisions = pd.concat(current_provisions)\n",
    "    old_provisions = pd.concat(old_provisions)\n",
    "    old_provisions['year'] += n # Match the year which we want to join onto\n",
    "\n",
    "    # Merge the provisions\n",
    "    all_provisions = pd.merge(current_provisions, old_provisions, on=['state', 'year'], suffixes=('', '_old'))\n",
    "\n",
    "    # Add provisions to feature_df and return the new feature_df\n",
    "    feature_df = pd.merge(feature_df, all_provisions, left_on=['this_year', 'state'], right_on=['year', 'state'])\n",
    "    return feature_df.drop('year', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include provision information\n",
    "feature_df = add_provisions(feature_df, provisions_df, useful_provisions_df, k=15, n=5)\n",
    "\n",
    "# Exclude states that have a very low average number of deaths. In this case, we choose 2 as our threshold\n",
    "average_deaths = feature_df.groupby('state')['next_deaths'].mean()\n",
    "excluded = average_deaths[average_deaths < 2].index\n",
    "states = average_deaths[average_deaths >= 2].index\n",
    "\n",
    "# Filter out the states\n",
    "feature_df = feature_df[~feature_df['state'].isin(excluded)]\n",
    "\n",
    "# Add the label. The label will be whether gun violence will increase by more than 30% for a given month\n",
    "feature_df['label'] = (feature_df['rate_change'] > 0.3).astype(int)\n",
    "# Sort the data chronologically by date, then alphabetically by state name  \n",
    "feature_df = feature_df.sort_values(['next_date', 'state']).reset_index().drop('index', axis=1)\n",
    "\n",
    "# Drop the columns directly related to the label\n",
    "feature_df = feature_df.drop(['rate_change', 'next_deaths'], axis=1)  \n",
    "# Drop columns regarding year \n",
    "feature_df = feature_df.drop(['next_year', 'this_year'], axis=1)\n",
    "\n",
    "# By dropping null values, we lose the first month because there is no previous date for the first month\n",
    "feature_df = feature_df.dropna()\n",
    "\n",
    "# Make placeholders for two additional features: one for predictions of this month, and one for next month\n",
    "feature_df['this_preds'] = 0\n",
    "feature_df['next_preds'] = 0\n",
    "\n",
    "# Finally, make a weekly DataFrame for the time series predictions\n",
    "weekly_df = by_date_total_df.resample('W').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "Now that all the `feature_df` is ready with all of the features and information, it's time to model the data. Here is an image of the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, define need a function to easily get time series predictions\n",
    "def get_trend_predictions(weekly_df, date, state, n_periods=14):\n",
    "    time_series = weekly_df[:date][state]\n",
    "    time_series = time_series.reset_index()\n",
    "    time_series.columns = ['ds', 'y']\n",
    "\n",
    "    # Model the data and make predictions\n",
    "    model = Prophet(yearly_seasonality=True)\n",
    "    model = model.fit(time_series)\n",
    "    future = model.make_future_dataframe(periods=n_periods)\n",
    "    output = model.predict(future)[['ds', 'yhat']]\n",
    "\n",
    "    # Resample monthly and add the state as a column\n",
    "    output = output.set_index('ds').resample('M').sum()\n",
    "\n",
    "    # Get predictions for this month and next month\n",
    "    this_output = output[:date].reset_index()\n",
    "    this_output.columns = ['this_date', 'this_preds']\n",
    "    next_output = output.reset_index().shift(-1).dropna()\n",
    "    next_output.columns = ['next_date', 'next_preds']\n",
    "\n",
    "    return this_output, next_output\n",
    "\n",
    "# Update trend predictions up to the current observation's state\n",
    "def update_trends(feature_df, weekly_df, date, states): \n",
    "    for state in states:\n",
    "        this_trend_preds, next_trend_preds = get_trend_predictions(weekly_df, this_date, state)\n",
    "        to_update = (feature_df['state'] == state) & (feature_df['this_date'] <= this_date)\n",
    "        feature_df.loc[to_update, 'this_preds'] = this_trend_preds['this_preds'].values\n",
    "        feature_df.loc[to_update, 'next_preds'] = next_trend_preds['next_preds'].values\n",
    "    \n",
    "    return feature_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are columns unnecessary classification models;drop them when feeding features to the models\n",
    "extra_columns = ['this_date', 'next_date', 'state', 'label']\n",
    "dates = feature_df['next_date'].unique()\n",
    "\n",
    "# Make a list w/ pairs of models and parameters to look through when doing GridSearchCV\n",
    "\n",
    "# Parameters for XGBClassifier\n",
    "xgb_params = {\n",
    "  'max_depth': [3, 5, 7, 9], \n",
    "  'n_estimators': [30, 50, 100, 300, 500, 700]\n",
    "}\n",
    "\n",
    "# Parameters for LogisitcRegression\n",
    "logi_regr_params = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [1e-2, 1e-1, 1, 10, 1e2, 1e3, 1e4, 1e5, 1e6]\n",
    "}\n",
    "\n",
    "# Parameters for RandomForest\n",
    "random_forest_params = {\n",
    "  'max_depth': [3, 5, 7, 9], \n",
    "  'n_estimators': [30, 50, 100, 300, 500, 700]\n",
    "}\n",
    "\n",
    "# Parameters for AdaBoost\n",
    "adaboost_params = {\n",
    "  'n_estimators': [30, 50, 100, 300, 500, 700]\n",
    "}\n",
    "\n",
    "# Parameters for GaussianNB\n",
    "percent_positive = feature_df['label'].mean() # Percentage of positive labels\n",
    "percent_negative = 1 - percent_positive # Percentage of negative features \n",
    "bayes_params = {'priors': [None, [percent_negative, percent_positive]]}\n",
    "\n",
    "# model{ 'model name': (model_object, parameters) } \n",
    "models = {\n",
    "    'XGBoost': (XGBClassifier(), xgb_params), \n",
    "    'Logistic Reg': (LogisticRegression(), logi_regr_params),\n",
    "    'Random Forest': (RandomForestClassifier(), random_forest_params),\n",
    "    'AdaBoost': (AdaBoostClassifier(), adaboost_params),\n",
    "    'Gaussian NB': (GaussianNB(), bayes_params)   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train each model on 2014 and 2015, then make predictions on every month for 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating trends for with this_date 2015-12-31...\n",
      "Training XGBoost | next_date: 2016-01-31... \n",
      "Training Logistic Reg | next_date: 2016-01-31... \n",
      "Training Random Forest | next_date: 2016-01-31... \n",
      "Training AdaBoost | next_date: 2016-01-31... \n",
      "Training Gaussian NB | next_date: 2016-01-31... \n",
      "Updating trends for with this_date 2016-01-31...\n",
      "Training XGBoost | next_date: 2016-02-29... \n",
      "Training Logistic Reg | next_date: 2016-02-29... \n",
      "Training Random Forest | next_date: 2016-02-29... \n",
      "Training AdaBoost | next_date: 2016-02-29... \n",
      "Training Gaussian NB | next_date: 2016-02-29... \n",
      "Updating trends for with this_date 2016-02-29...\n",
      "Training XGBoost | next_date: 2016-03-31... \n",
      "Training Logistic Reg | next_date: 2016-03-31... \n",
      "Training Random Forest | next_date: 2016-03-31... \n",
      "Training AdaBoost | next_date: 2016-03-31... \n",
      "Training Gaussian NB | next_date: 2016-03-31... \n",
      "Updating trends for with this_date 2016-03-31...\n",
      "Training XGBoost | next_date: 2016-04-30... \n",
      "Training Logistic Reg | next_date: 2016-04-30... \n",
      "Training Random Forest | next_date: 2016-04-30... \n",
      "Training AdaBoost | next_date: 2016-04-30... \n",
      "Training Gaussian NB | next_date: 2016-04-30... \n",
      "Updating trends for with this_date 2016-04-30...\n",
      "Training XGBoost | next_date: 2016-05-31... \n",
      "Training Logistic Reg | next_date: 2016-05-31... \n",
      "Training Random Forest | next_date: 2016-05-31... \n",
      "Training AdaBoost | next_date: 2016-05-31... \n",
      "Training Gaussian NB | next_date: 2016-05-31... \n",
      "Updating trends for with this_date 2016-05-31...\n",
      "Training XGBoost | next_date: 2016-06-30... \n",
      "Training Logistic Reg | next_date: 2016-06-30... \n",
      "Training Random Forest | next_date: 2016-06-30... \n",
      "Training AdaBoost | next_date: 2016-06-30... \n",
      "Training Gaussian NB | next_date: 2016-06-30... \n",
      "Updating trends for with this_date 2016-06-30...\n",
      "Training XGBoost | next_date: 2016-07-31... \n",
      "Training Logistic Reg | next_date: 2016-07-31... \n",
      "Training Random Forest | next_date: 2016-07-31... \n",
      "Training AdaBoost | next_date: 2016-07-31... \n",
      "Training Gaussian NB | next_date: 2016-07-31... \n",
      "Updating trends for with this_date 2016-07-31...\n",
      "Training XGBoost | next_date: 2016-08-31... \n",
      "Training Logistic Reg | next_date: 2016-08-31... \n",
      "Training Random Forest | next_date: 2016-08-31... \n",
      "Training AdaBoost | next_date: 2016-08-31... \n",
      "Training Gaussian NB | next_date: 2016-08-31... \n",
      "Updating trends for with this_date 2016-08-31...\n",
      "Training XGBoost | next_date: 2016-09-30... \n",
      "Training Logistic Reg | next_date: 2016-09-30... \n",
      "Training Random Forest | next_date: 2016-09-30... \n",
      "Training AdaBoost | next_date: 2016-09-30... \n",
      "Training Gaussian NB | next_date: 2016-09-30... \n",
      "Updating trends for with this_date 2016-09-30...\n",
      "Training XGBoost | next_date: 2016-10-31... \n",
      "Training Logistic Reg | next_date: 2016-10-31... \n",
      "Training Random Forest | next_date: 2016-10-31... \n",
      "Training AdaBoost | next_date: 2016-10-31... \n",
      "Training Gaussian NB | next_date: 2016-10-31... \n",
      "Updating trends for with this_date 2016-10-31...\n",
      "Training XGBoost | next_date: 2016-11-30... \n",
      "Training Logistic Reg | next_date: 2016-11-30... \n",
      "Training Random Forest | next_date: 2016-11-30... \n",
      "Training AdaBoost | next_date: 2016-11-30... \n",
      "Training Gaussian NB | next_date: 2016-11-30... \n",
      "Updating trends for with this_date 2016-11-30...\n",
      "Training XGBoost | next_date: 2016-12-31... \n",
      "Training Logistic Reg | next_date: 2016-12-31... \n",
      "Training Random Forest | next_date: 2016-12-31... \n",
      "Training AdaBoost | next_date: 2016-12-31... \n",
      "Training Gaussian NB | next_date: 2016-12-31... \n"
     ]
    }
   ],
   "source": [
    "# Start at 2016-01-31 and stop (before) 2017-01-31 \n",
    "start = np.where(dates == '2016-01-31')[0][0]\n",
    "end = np.where(dates == '2017-01-31')[0][0]\n",
    "\n",
    "training_history = defaultdict(list)\n",
    "testing_history = defaultdict(list)\n",
    "testing_history_probs = defaultdict(list)\n",
    "trained_models = {}\n",
    "for index in range(start, end):\n",
    "    this_date = dates[index - 1]\n",
    "    next_date = dates[index]\n",
    "    \n",
    "    print(\"Updating trends for with this_date {}...\".format(this_date))\n",
    "    feature_df = update_trends(feature_df, weekly_df, this_date, states) \n",
    "\n",
    "    # Training data is all data before next_date\n",
    "    # Testing data all data during next_date\n",
    "    train_date_filter = feature_df['next_date'] < next_date\n",
    "    test_date_filter = feature_df['next_date'] == next_date\n",
    "    \n",
    "    X_train = feature_df.loc[train_date_filter].drop(extra_columns, axis=1).values\n",
    "    y_train = feature_df.loc[train_date_filter, 'label']\n",
    "\n",
    "    X_test = feature_df.loc[test_date_filter].drop(extra_columns, axis=1).values\n",
    "    y_test = feature_df.loc[test_date_filter, 'label']\n",
    "    \n",
    "    meta_train = []\n",
    "    meta_test = []\n",
    "    predictions = {}\n",
    "    for name, (model, parameters) in models.items():\n",
    "        print(\"Training {} | next_date: {}... \".format(name, next_date))\n",
    "        clf = GridSearchCV(model, parameters)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on training set\n",
    "        train_preds = clf.predict(X_train)\n",
    "        test_preds = clf.predict(X_test)\n",
    "        train_probs = clf.best_estimator_.predict_proba(X_train)[:, 0]\n",
    "        test_probs = clf.best_estimator_.predict_proba(X_test)[:, 0]\n",
    "        # Make meta features to train the meta model on\n",
    "        meta_train.append(train_probs)\n",
    "        meta_test.append(test_probs)\n",
    "    \n",
    "        # Keep track of the predictions\n",
    "        training_history[name].append(train_preds)\n",
    "        testing_history[name].extend(test_preds)\n",
    "        testing_history_probs[name].extend(test_probs)\n",
    "        \n",
    "        # Remember the last model\n",
    "        trained_models[name] = clf\n",
    "    \n",
    "    # Take transpose of meta features so that observations are rows\n",
    "    meta_train = np.array(meta_train).T\n",
    "    meta_test = np.array(meta_test).T\n",
    "    \n",
    "    # Create and train the meta model\n",
    "    clf = GridSearchCV(XGBClassifier(), xgb_params)\n",
    "    clf.fit(meta_train, y_train)\n",
    "    \n",
    "    # Make training and testing predictions\n",
    "    train_preds = clf.predict(meta_train)\n",
    "    test_preds = clf.predict(meta_test)\n",
    "\n",
    "    # Keep track of the predictions\n",
    "    training_history['meta'].append(train_preds)\n",
    "    testing_history['meta'].extend(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs = []\n",
    "for v in testing_history_probs.values():\n",
    "    all_probs.append(v)\n",
    "    \n",
    "all_probs = np.array(all_probs).T\n",
    "vote_by_probs = [int(x > 0.5) for x in all_probs.mean(axis=1)]\n",
    "\n",
    "all_preds = []\n",
    "for v in testing_history.values():\n",
    "    all_preds.append(v)\n",
    "    \n",
    "all_preds = np.array(all_preds).T\n",
    "vote_by_preds = [int(x > 0.5) for x in all_preds.mean(axis=1)]\n",
    "\n",
    "testing_history['vote_by_probs'] = vote_by_probs\n",
    "testing_history['vote_by_preds'] = vote_by_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: 0.7732558139534884 \n",
      "Recall: 0.0423728813559322**\n",
      "Precision: 0.5555555555555556\n",
      "[[394   4]\n",
      " [113   5]]\n",
      "----------\n",
      "Logistic Reg: 0.7732558139534884 \n",
      "Recall: 0.025423728813559324**\n",
      "Precision: 0.6\n",
      "[[396   2]\n",
      " [115   3]]\n",
      "----------\n",
      "Random Forest: 0.7596899224806202 \n",
      "Recall: 0.059322033898305086**\n",
      "Precision: 0.35\n",
      "[[385  13]\n",
      " [111   7]]\n",
      "----------\n",
      "AdaBoost: 0.7732558139534884 \n",
      "Recall: 0.0423728813559322**\n",
      "Precision: 0.5555555555555556\n",
      "[[394   4]\n",
      " [113   5]]\n",
      "----------\n",
      "Gaussian NB: 0.3992248062015504 \n",
      "Recall: 0.864406779661017**\n",
      "Precision: 0.25757575757575757\n",
      "[[104 294]\n",
      " [ 16 102]]\n",
      "----------\n",
      "meta: 0.7073643410852714 \n",
      "Recall: 0.2457627118644068**\n",
      "Precision: 0.31868131868131866\n",
      "[[336  62]\n",
      " [ 89  29]]\n",
      "----------\n",
      "vote_by_probs: 0.2189922480620155 \n",
      "Recall: 0.923728813559322**\n",
      "Precision: 0.21669980119284293\n",
      "[[  4 394]\n",
      " [  9 109]]\n",
      "----------\n",
      "vote_by_preds: 0.7693798449612403 \n",
      "Recall: 0.025423728813559324**\n",
      "Precision: 0.42857142857142855\n",
      "[[394   4]\n",
      " [115   3]]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "truth = feature_df[(feature_df['next_date'] >= '2016-01-31') & (feature_df['next_date'] < '2017-01-31')]['label']\n",
    "for name, preds in testing_history.items():\n",
    "    plt.plot()\n",
    "    print(\"{}: {} \".format(name, accuracy_score(truth, preds)))\n",
    "    cm = confusion_matrix(truth, preds)\n",
    "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "#     print(\"True Negative: {}\".format(tn))\n",
    "#     print(\"False Positive: {}\".format(fp))\n",
    "#     print(\"False Negative: {}\".format(fn))\n",
    "#     print(\"True Positive: {}\".format(tp))\n",
    "    print(\"Recall: {}**\".format(recall))\n",
    "    print(\"Precision: {}\".format(precision))\n",
    "    print(cm)\n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>Logistic Reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cap14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>universalpermit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>dvrosurrenderdating</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>cap16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>capuses</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>dvrosurrender</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>statechecksh</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>age21handgunsale</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>violentpartial</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>permitlaw</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>permith</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>immunity</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>dvrosurrender_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>capuses_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mcdvsurrender</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>cap14_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mcdvdating</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>dvrosurrenderdating_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>immunity_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>nosyg_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>permith_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>permitlaw_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>violentpartial_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>statechecksh_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>age21handgunsale_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>cap16_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>mcdvdating_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>mcdvsurrender_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>universalpermit_old</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>robbery_crime_old</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>2.513123e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>burglary_crime_old</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>-1.511827e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>lawtotal</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>lawtotal_old</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>-1.362462e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last_year</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>-3.539986e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>property_crime_old</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>-1.690342e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>violent_crime</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>-6.314213e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>burglary_crime</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>1.125569e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>violent_crime_old</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>3.915232e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>property_crime</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>1.435510e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>us_decile</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>robbery_crime</td>\n",
       "      <td>0.008104</td>\n",
       "      <td>-1.508444e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>assault_crime_old</td>\n",
       "      <td>0.008104</td>\n",
       "      <td>-5.184021e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rape_crime</td>\n",
       "      <td>0.009724</td>\n",
       "      <td>-1.098943e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>democrat</td>\n",
       "      <td>0.009724</td>\n",
       "      <td>8.793534e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vehicle_theft_crime_old</td>\n",
       "      <td>0.009724</td>\n",
       "      <td>3.720844e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>larceny_theft_crime_old</td>\n",
       "      <td>0.011345</td>\n",
       "      <td>-1.012788e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>all</td>\n",
       "      <td>0.012966</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>assault_crime</td>\n",
       "      <td>0.014587</td>\n",
       "      <td>7.854556e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vehicle_theft_crime</td>\n",
       "      <td>0.016207</td>\n",
       "      <td>-3.229534e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>wine</td>\n",
       "      <td>0.017828</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>income</td>\n",
       "      <td>0.022690</td>\n",
       "      <td>2.885127e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>beer</td>\n",
       "      <td>0.024311</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>spirits</td>\n",
       "      <td>0.024311</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>population</td>\n",
       "      <td>0.024311</td>\n",
       "      <td>-1.086210e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>murder_crime_old</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>-3.794664e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>murder_crime</td>\n",
       "      <td>0.037277</td>\n",
       "      <td>8.748678e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rape_crime_old</td>\n",
       "      <td>0.043760</td>\n",
       "      <td>2.606957e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>this_preds</td>\n",
       "      <td>0.077796</td>\n",
       "      <td>-6.796087e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>next_preds</td>\n",
       "      <td>0.251216</td>\n",
       "      <td>-2.389827e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>this_deaths</td>\n",
       "      <td>0.304700</td>\n",
       "      <td>2.811004e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   features   XGBoost  Logistic Reg\n",
       "31                    cap14  0.000000  0.000000e+00\n",
       "33          universalpermit  0.000000  0.000000e+00\n",
       "32      dvrosurrenderdating  0.000000  0.000000e+00\n",
       "36                    cap16  0.000000  0.000000e+00\n",
       "30                  capuses  0.000000  0.000000e+00\n",
       "29            dvrosurrender  0.000000  0.000000e+00\n",
       "37             statechecksh  0.000000  0.000000e+00\n",
       "38         age21handgunsale  0.000000  0.000000e+00\n",
       "39           violentpartial  0.000000  0.000000e+00\n",
       "40                permitlaw  0.000000  0.000000e+00\n",
       "41                  permith  0.000000  0.000000e+00\n",
       "43                 immunity  0.000000  0.000000e+00\n",
       "45        dvrosurrender_old  0.000000  0.000000e+00\n",
       "46              capuses_old  0.000000  0.000000e+00\n",
       "34            mcdvsurrender  0.000000  0.000000e+00\n",
       "47                cap14_old  0.000000  0.000000e+00\n",
       "35               mcdvdating  0.000000  0.000000e+00\n",
       "48  dvrosurrenderdating_old  0.000000  0.000000e+00\n",
       "59             immunity_old  0.000000  0.000000e+00\n",
       "58                nosyg_old  0.000000  0.000000e+00\n",
       "57              permith_old  0.000000  0.000000e+00\n",
       "56            permitlaw_old  0.000000  0.000000e+00\n",
       "55       violentpartial_old  0.000000  0.000000e+00\n",
       "53         statechecksh_old  0.000000  0.000000e+00\n",
       "54     age21handgunsale_old  0.000000  0.000000e+00\n",
       "52                cap16_old  0.000000  0.000000e+00\n",
       "51           mcdvdating_old  0.000000  0.000000e+00\n",
       "50        mcdvsurrender_old  0.000000  0.000000e+00\n",
       "49      universalpermit_old  0.000000  0.000000e+00\n",
       "15        robbery_crime_old  0.001621  2.513123e-04\n",
       "..                      ...       ...           ...\n",
       "17       burglary_crime_old  0.001621 -1.511827e-05\n",
       "44                 lawtotal  0.003241  0.000000e+00\n",
       "60             lawtotal_old  0.003241 -1.362462e-03\n",
       "0                 last_year  0.003241 -3.539986e-04\n",
       "12       property_crime_old  0.003241 -1.690342e-06\n",
       "2             violent_crime  0.003241 -6.314213e-05\n",
       "8            burglary_crime  0.004862  1.125569e-05\n",
       "11        violent_crime_old  0.004862  3.915232e-05\n",
       "3            property_crime  0.004862  1.435510e-06\n",
       "25                us_decile  0.006483  0.000000e+00\n",
       "6             robbery_crime  0.008104 -1.508444e-04\n",
       "16        assault_crime_old  0.008104 -5.184021e-05\n",
       "5                rape_crime  0.009724 -1.098943e-04\n",
       "26                 democrat  0.009724  8.793534e-03\n",
       "19  vehicle_theft_crime_old  0.009724  3.720844e-05\n",
       "18  larceny_theft_crime_old  0.011345 -1.012788e-06\n",
       "24                      all  0.012966  0.000000e+00\n",
       "7             assault_crime  0.014587  7.854556e-05\n",
       "10      vehicle_theft_crime  0.016207 -3.229534e-05\n",
       "22                     wine  0.017828  0.000000e+00\n",
       "20                   income  0.022690  2.885127e-07\n",
       "21                     beer  0.024311  0.000000e+00\n",
       "23                  spirits  0.024311  0.000000e+00\n",
       "1                population  0.024311 -1.086210e-07\n",
       "13         murder_crime_old  0.025932 -3.794664e-03\n",
       "4              murder_crime  0.037277  8.748678e-04\n",
       "14           rape_crime_old  0.043760  2.606957e-04\n",
       "61               this_preds  0.077796 -6.796087e-02\n",
       "62               next_preds  0.251216 -2.389827e-01\n",
       "28              this_deaths  0.304700  2.811004e-01\n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances_df = pd.DataFrame()\n",
    "importances_df['features'] = feature_df.drop(extra_columns, axis=1).columns\n",
    "importances_df['XGBoost'] = trained_models['XGBoost'].best_estimator_.feature_importances_\n",
    "importances_df['Logistic Reg'] = trained_models['Logistic Reg'].best_estimator_.coef_[0]\n",
    "# importances_df.sort_values('Logistic Reg')\n",
    "importances_df.sort_values('XGBoost')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Cleaning the  Data\n",
    "In this notebook, we'll take the raw data and reorganize them so that we can use them for visualization and a predictive model. These are the files we will be working with:\n",
    "```\n",
    "incidents.csv                 List of gun violence incidents from January 2014 - March 2018\n",
    "population.csv                Population from 2000 - 2017 intercensal estimates for July\n",
    "other_crime_annual.csv        Annual sums of crimes by state from 2010 - 2016\n",
    "income.csv                    Annual average personal income by state from 2009-2017         \n",
    "annual_gun_deaths.csv         Annual deaths by guns (homicides only) by state from 1999-2013\n",
    "alcohol.csv                   Annual alcohol consumption by state from 1977-2016\n",
    "provisions.csv                List of provisions in place by each state for the years 1991-2017\n",
    "election_results.csv          List of presidential election results by state from years 2000-2016\n",
    "registrations.csv             List of weapons registrations by state for years 2011-2017\n",
    "```\n",
    "For more information on where these datasets came from, see the writeup. Our goal is to make several DataFrames which will be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy and pandas for manipulating the data\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_incidents_file = './data/raw/incidents.csv.gz' # zipped because file is too big\n",
    "population_file = './data/raw/population.csv'\n",
    "crime_file = './data/raw/other_crime_annual.csv'\n",
    "income_file = './data/raw/income.csv'\n",
    "annual_file = './data/raw/annual_gun_deaths.csv'\n",
    "alcohol_file = './data/raw/alcohol.csv'\n",
    "provisions_file = './data/raw/provisions.csv'\n",
    "election_file = './data/raw/election_results.csv'\n",
    "registrations_file = './data/raw/registrations.csv'\n",
    "\n",
    "daily_incidents_df = pd.read_csv(daily_incidents_file, parse_dates=True, compression='gzip')\n",
    "population_df = pd.read_csv(population_file, parse_dates=True, index_col=0)\n",
    "annual_gun_deaths_df = pd.read_csv(annual_file, parse_dates=True)\n",
    "crime_df = pd.read_csv(crime_file, parse_dates=True)\n",
    "income_df = pd.read_csv(income_file, parse_dates=True)\n",
    "alcohol_df = pd.read_csv(alcohol_file, parse_dates=True)\n",
    "provisions_df = pd.read_csv(provisions_file, parse_dates=True)\n",
    "election_df = pd.read_csv(election_file)\n",
    "registrations_df = pd.read_csv(registrations_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incidents\n",
    "### daily_incidents_df and population_df\n",
    "Goals: \n",
    "\n",
    "    lat_long_df         Incidents with latitude and longitude coordinates (2014-2017)\n",
    "    feature_df          Daily incidents per state, each with features from the previous year (2014-2017)\n",
    "    by_date_total_df    Daily gun homicides per state indexed by date with states in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "incident_id                         0\n",
       "date                                0\n",
       "state                               0\n",
       "city_or_county                      0\n",
       "n_killed                            0\n",
       "n_injured                           0\n",
       "incident_url                        0\n",
       "incident_url_fields_missing         0\n",
       "incident_characteristics          327\n",
       "source_url                        468\n",
       "sources                           610\n",
       "longitude                        7923\n",
       "latitude                         7923\n",
       "congressional_district          11945\n",
       "address                         16497\n",
       "participant_type                24864\n",
       "participant_status              27627\n",
       "state_senate_district           32336\n",
       "participant_gender              36363\n",
       "state_house_district            38773\n",
       "participant_age_group           42120\n",
       "notes                           81018\n",
       "participant_age                 92299\n",
       "n_guns_involved                 99452\n",
       "gun_type                        99452\n",
       "gun_stolen                      99499\n",
       "participant_name               122254\n",
       "location_description           197589\n",
       "participant_relationship       223904\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_count = daily_incidents_df.isnull().sum()\n",
    "null_count.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be many missing values about the details of each incident. However, the 'state' and 'date' columns have no missing values, which is good for our objective (examining gun violence trends for each state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First let's make some columns that we'll need\n",
    "daily_incidents_df['date'] = pd.to_datetime(daily_incidents_df['date']) # Turn the date into a datetime\n",
    "daily_incidents_df['year'] = daily_incidents_df['date'].dt.year # Create a column for just the year\n",
    "\n",
    "# Upon examining the data, it seems that records before 2014 have missing data, so we'll exclude them\n",
    "daily_incidents_df = daily_incidents_df[daily_incidents_df['year'] >= 2014]\n",
    "\n",
    "# Get number of casualties for each state, indexed by date\n",
    "by_date_total_df = daily_incidents_df.groupby(['date', 'state'])['n_killed'].sum().unstack()\n",
    "by_date_total_df = by_date_total_df.fillna(0) # Some days had no incidents (no entries). Fill with 0s\n",
    "\n",
    "by_date_total_df.to_csv('./data/cleaned/by_date_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get latitude and longitude information and save it\n",
    "lat_long_df = daily_incidents_df[['state', 'latitude', 'longitude', 'n_killed']].dropna()\n",
    "lat_long_df.to_csv('./data/cleaned/lat_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a feature DataFrame to store all of our features (to be used later in our model)\n",
    "feature_df = by_date_total_df.resample('M').sum().stack().reset_index()\n",
    "feature_df.columns = ['next_date', 'state', 'next_deaths']\n",
    "\n",
    "# Add next year (the year which we want to predict on) and the previous year\n",
    "feature_df['next_year'] = feature_df['next_date'].apply(lambda x: x.year)\n",
    "feature_df['this_year'] = feature_df['next_year'] - 1\n",
    "feature_df['last_year'] = feature_df['next_year'] - 2\n",
    "\n",
    "# Add population data from population_df to feature_df\n",
    "get_population = lambda x: population_df.loc[x['state'], str(x['this_year'])]\n",
    "feature_df['population'] = feature_df[['state', 'this_year']].apply(get_population, axis=1)\n",
    "    \n",
    "# Reformat population data\n",
    "population_df = population_df.stack().reset_index()\n",
    "population_df.columns = ['state', 'year', 'population']\n",
    "population_df['year'] = population_df['year'].astype(int)\n",
    "\n",
    "# Put observations in each row for annual_gun_deaths_df; data is from 1999-2013\n",
    "annual_1999_2013_df = annual_gun_deaths_df.set_index('state').stack().reset_index()\n",
    "annual_1999_2013_df.columns = ['state', 'year', 'gun_deaths']\n",
    "\n",
    "# Sum incidents annually and make each row an observation w/ state, year, and gun_deaths \n",
    "annual_2014_2017 = by_date_total_df[:'2017'].resample('A').sum().stack().reset_index()\n",
    "annual_2014_2017['date'] = annual_2014_2017['date'].apply(lambda x: x.year)\n",
    "\n",
    "# Rearrange columns and concat the dataframes\n",
    "annual_2014_2017.columns = ['year', 'state', 'gun_deaths']\n",
    "annual_2014_2017 = annual_2014_2017[['state', 'year', 'gun_deaths']]\n",
    "\n",
    "# Note: later, we lose year 1999 when we merge with population since population_df goes from 2000-2017 only\n",
    "annual_2000_2017_df = pd.concat([annual_1999_2013_df, annual_2014_2017])\n",
    "annual_2000_2017_df['year'] = annual_2000_2017_df['year'].astype(int)\n",
    "\n",
    "# Add population data to annual_2000_2017\n",
    "annual_2000_2017_df = pd.merge(annual_2000_2017_df, population_df, how='left')\n",
    "annual_2000_2017_df = annual_2000_2017_df.sort_values(['state', 'year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Crime\n",
    "We'll be working with this data:\n",
    "    \n",
    "    crime_df                 Annual crime data (2010-2016) from disastercenter.com/crime/  \n",
    "    annual_gun_deaths_df     Annual gun homicides by state (1999-2013) from gunpolicy.org\n",
    "And creating/updating these DataFrames:\n",
    "\n",
    "    annual_2000_2017_df      DataFrame that holds annual gun death info from 2000-2017\n",
    "    feature_df               Update with crime features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: other_crime here is defined by crimes not including murder\n",
    "crime_df = crime_df.drop(['population', 'index'], axis=1)\n",
    "crime_df['year'] = crime_df['year'].astype(int)\n",
    "\n",
    "# Update our feature dataframe with the crime rate for this_year and last_year (so we can see difference)\n",
    "feature_df = pd.merge(feature_df, crime_df, left_on=['state','this_year'], \n",
    "                                            right_on=['state', 'year'])\n",
    "feature_df = feature_df.drop('year', axis=1)\n",
    "\n",
    "feature_df = pd.merge(feature_df, crime_df, left_on=['state','last_year'], \n",
    "                                            right_on=['state', 'year'], suffixes=('', '_old'))\n",
    "feature_df = feature_df.drop('year', axis=1)\n",
    "\n",
    "\n",
    "crime_df['other_crime'] = crime_df[['rape_crime', 'robbery_crime', 'assault_crime', \n",
    "                                'burglary_crime', 'larceny_theft_crime', 'vehicle_theft_crime']].sum(axis=1)\n",
    "\n",
    "annual_2000_2017_df = pd.merge(annual_2000_2017_df, crime_df, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Personal Income\n",
    "We'll be working with this data:\n",
    "    \n",
    "    income_df               Personal income per capita (2009-2017) from US Bureau of Economic Analysis\n",
    "Goals:\n",
    "    \n",
    "    annual_2000_2017_df    Update with personal income per capita\n",
    "    feature_df              Update with personal income per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add income data\n",
    "income_by_state_df = income_df.set_index('state').stack().reset_index()\n",
    "income_by_state_df.columns = ['state', 'year', 'income']\n",
    "income_by_state_df['year'] = income_by_state_df['year'].astype(int)\n",
    "\n",
    "annual_2000_2017_df = pd.merge(annual_2000_2017_df, income_by_state_df, how='left')\n",
    "feature_df = pd.merge(feature_df, income_by_state_df, left_on=['state', 'this_year'], \n",
    "                                                      right_on=['state', 'year'])\n",
    "feature_df = feature_df.drop('year', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Alcohol\n",
    "### alcohol_df\n",
    "Goals:\n",
    "\n",
    "    annual_2000_2017_df    update with avg total alcohol consumption \n",
    "    feature_df              update with all alcohol features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge the alcohol features into the annual and feature data frames\n",
    "annual_2000_2017_df = pd.merge(annual_2000_2017_df, alcohol_df, how='left')\n",
    "feature_df = pd.merge(feature_df, alcohol_df, left_on=['state', 'this_year'], \n",
    "                                              right_on=['state', 'year'])\n",
    "feature_df = feature_df.drop('year', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provisions\n",
    "There are a lot of provisions, so we will selectively add them to the DataFrames later when we need them. \n",
    "For now, we update `annual_2000_2017_df` with the total number of provisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['state', 'year', 'lawtotal']\n",
    "annual_2000_2017_df = pd.merge(annual_2000_2017_df, provisions_df[columns], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Election Results\n",
    "### election_df\n",
    "Goals:\n",
    "\n",
    "    annual_2000_2017_df      Update with election results\n",
    "    feature_df               Update with election results from previous year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, let's expand the election_df s.t. it has entries for non-election years with values\n",
    "# from the previous election. This way, we can just merge them with the other dfs later\n",
    "election_expand = []\n",
    "for i in range(4):\n",
    "    temp_df = election_df.copy()\n",
    "    temp_df['year'] = election_df['year'] + i\n",
    "    election_expand.append(temp_df)\n",
    "\n",
    "election_df = pd.concat(election_expand)\n",
    "\n",
    "# Update with the election information\n",
    "annual_2000_2017_df = pd.merge(annual_2000_2017_df, election_df, how='left')\n",
    "\n",
    "feature_df = pd.merge(feature_df, election_df, left_on=['state', 'this_year'], right_on=['state', 'year'])\n",
    "feature_df = feature_df.drop('year', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registrations\n",
    "### registrations_df\n",
    "Goals:\n",
    "\n",
    "    annual_2000_2017_df      Update with registrations info\n",
    "    feature_df               Update with registrations info from previous year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the annual_2000_2017_df with the registrations\n",
    "annual_2000_2017_df = pd.merge(annual_2000_2017_df, registrations_df, how='left')\n",
    "\n",
    "# Put gun registration data\n",
    "feature_df = pd.merge(feature_df, registrations_df, left_on=['state', 'this_year'], \n",
    "                                                    right_on=['state', 'year'])\n",
    "\n",
    "feature_df = feature_df = feature_df.drop('year', axis=1)\n",
    "\n",
    "feature_df = pd.merge(feature_df, registrations_df, left_on=['state','last_year'], \n",
    "                                                    right_on=['state', 'year'], suffixes=('', '_old'))\n",
    "feature_df = feature_df.drop('year', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "Add a column to `annual_2000_2017_df` for normalized crime and gun homicides\n",
    "\n",
    "Add the percent change from this year to the next year on each row of `feature_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add features normalized by population to the annual dataframe\n",
    "annual_population = annual_2000_2017_df['population']\n",
    "annual_2000_2017_df['gun_deaths_norm'] = annual_2000_2017_df['gun_deaths'] / annual_population * 100000\n",
    "annual_2000_2017_df['other_crime_norm'] = annual_2000_2017_df['other_crime'] / annual_population * 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our predictions, we will be using the change in gun violence from the previous month. \n",
    "# Let's add that feature here:\n",
    "\n",
    "# Iterate through states and calculate the change of each state and keep track of deaths from last date\n",
    "states = by_date_total_df.columns\n",
    "rate_changes = []\n",
    "this_deaths = []\n",
    "this_dates = []\n",
    "for state in states:\n",
    "    deaths = feature_df[feature_df['state'] == state]['next_deaths']\n",
    "    rate_changes.append((deaths.shift() - deaths) / (deaths + 1))\n",
    "    this_deaths.append(deaths.shift())\n",
    "    this_dates.append(feature_df[feature_df['state'] == state]['next_date'].shift())\n",
    "    \n",
    "# Append the rate change and add to feature_df. Note: this is something we want to predict; not a feature.\n",
    "feature_df['rate_change'] = pd.concat(rate_changes)\n",
    "\n",
    "# We could also use the previous month's violence rate\n",
    "feature_df['this_deaths'] = pd.concat(this_deaths)\n",
    "\n",
    "# And the this month's date\n",
    "feature_df['this_date'] = pd.concat(this_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save annual and feature DataFrames\n",
    "annual_2000_2017_df.to_csv('./data/cleaned/annual_gun.csv')\n",
    "feature_df.to_csv('./data/cleaned/feature.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To recap, here are the DataFrames that were saved:\n",
    "\n",
    "    lat_long_df                Incidents with latitude and longitude coordinates (2014-2017)\n",
    "    by_date_tot_df             Gun homicides aggregated daily and by state (2014-2017)\n",
    "    annual_2000_2017           Annual gun homicides with all other annual features (2000-2017)\n",
    "    feature_df                 Gun homicides aggregated monthly and by state, paired with annual features from\n",
    "                               the previous year (2014-2017)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
